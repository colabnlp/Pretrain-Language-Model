{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_crf_baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e4bb33f73394303a8afa4776c8faf3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0214674dd2ff4b669923db5fefcfe146",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5dc69c1a929e47e6be6dfb04e2c11621",
              "IPY_MODEL_aa924d8ef48c46b78e105ea5269683d5"
            ]
          }
        },
        "0214674dd2ff4b669923db5fefcfe146": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5dc69c1a929e47e6be6dfb04e2c11621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c6ab156ee3d54ea29b404dc114c954cb",
            "_dom_classes": [],
            "description": "Downloading",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 109540,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 109540,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a287e4d18b974a569ff8f878b356e507"
          }
        },
        "aa924d8ef48c46b78e105ea5269683d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_678a911f26f04292b280e698e7648eff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 110k/110k [00:00&lt;00:00, 620kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48d2737939934b1db2880de404ae62e8"
          }
        },
        "c6ab156ee3d54ea29b404dc114c954cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a287e4d18b974a569ff8f878b356e507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "678a911f26f04292b280e698e7648eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48d2737939934b1db2880de404ae62e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0a8fbefa8bb45998c5a6d678280dbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4b2489d430341a1855480decc83a9f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80423844fd5e435eafb8723aecb5bdc3",
              "IPY_MODEL_882344a397f64dd9b1c8e413596a6b51"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I5GMUBhNfZFW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a9aa463c-1efe-4408-931d-f25ddb69df93"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow==2.1.0\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
            "\r\u001b[K     |▋                               | 10kB 1.8MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 4.5MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 5.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 225kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 235kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 245kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 337kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 348kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 368kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 440kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 450kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 460kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 471kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 481kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 491kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\r\u001b[K     |▎                               | 10kB 4.9MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 8.7MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 12.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 14.9MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 17.3MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 71kB 22.1MB/s eta 0:00:01\r\u001b[K     |██▌                             | 81kB 23.9MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 25.8MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 27.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 27.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 27.7MB/s eta 0:00:01\r\u001b[K     |████                            | 133kB 27.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 143kB 27.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 153kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 163kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 174kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 204kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 215kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 235kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 245kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 256kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 266kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 276kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 286kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 296kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 307kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 317kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 327kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 337kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 348kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 358kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 368kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 378kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 389kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 399kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 409kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 419kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 430kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 440kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 450kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 460kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 471kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 481kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 491kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 501kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 512kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 522kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 532kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 542kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 552kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 563kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 573kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 583kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 593kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 604kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 614kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 624kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 634kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 645kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 655kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 665kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 675kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 686kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 696kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 706kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 716kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 727kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 737kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 747kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 757kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 768kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 778kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 788kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 798kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 808kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 819kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 829kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 839kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 849kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 860kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 870kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 880kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 890kB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 901kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 911kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 921kB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 931kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 942kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 952kB 27.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 962kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 972kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 983kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 993kB 27.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.0MB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.0MB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 27.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.0MB 27.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 27.7MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.5.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
            "\u001b[K     |████████████████████████████████| 3.7MB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 26.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=d01e7d703a2a857ac2cb7490b6e30ce07c25765e9a59bca23e9a046d68e1a512\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n",
            "Collecting tensorflow==2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d4/c0cd1057b331bc38b65478302114194bd8e1b9c2bbc06e300935c0e93d90/tensorflow-2.1.0-cp36-cp36m-manylinux2010_x86_64.whl (421.8MB)\n",
            "\u001b[K     |████████████████████████████████| 421.8MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
            "Collecting tensorboard<2.2.0,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/41/bbf49b61370e4f4d245d4c6051dfb6db80cec672605c91b1652ac8cc3d38/tensorboard-2.1.1-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.9MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
            "Collecting tensorflow-estimator<2.2.0,>=2.1.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/90/b77c328a1304437ab1310b463e533fa7689f4bfc41549593056d812fab8e/tensorflow_estimator-2.1.0-py2.py3-none-any.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 46.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (45.2.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hHz1jzC00vrQ",
        "outputId": "68eb06de-435e-41b0-a63d-742d5cf62084",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Mar  7 13:47:34 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDzTyqSDfsmu",
        "outputId": "66e7d991-c33d-4a60-9222-825a79569ed5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r41554Laf4uj",
        "outputId": "f7d4c75e-72c1-4e4e-b333-fd085bf9a0d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# load data\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "  gdd.download_file_from_google_drive(\n",
        "          file_id='1RFZmH6cLFbivA0VeDc6s56bRTgc2NhL1',\n",
        "          dest_path='NER_Data/vocab.txt',\n",
        "      )\n",
        "\n",
        "  gdd.download_file_from_google_drive(\n",
        "          file_id='1JqV332A6ZWZEHv64vzCFmSNVpC1Mox8J',\n",
        "          dest_path='NER_Data/msra.zip',\n",
        "          unzip=True\n",
        "      )\n",
        "  print('running in colab!')\n",
        "  MAIN_PATH = '/content/NER_Data/'\n",
        "except:\n",
        "  print('running in local environment!')\n",
        "  MAIN_PATH = './'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 1RFZmH6cLFbivA0VeDc6s56bRTgc2NhL1 into NER_Data/vocab.txt... Done.\n",
            "Downloading 1JqV332A6ZWZEHv64vzCFmSNVpC1Mox8J into NER_Data/msra.zip... Done.\n",
            "Unzipping...Done.\n",
            "running in colab!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NtzaciW3fZFc",
        "outputId": "e6854a44-a688-45d2-d0c1-6c4b4a0174ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# params for model\n",
        "model_config = dict(\n",
        "        target_size=7\n",
        "    )\n",
        "\n",
        "# params for data processing\n",
        "data_config = dict(\n",
        "        seq_len=200,\n",
        "        batch_size=8,\n",
        "    )\n",
        "\n",
        "# params for model training\n",
        "train_config = dict(\n",
        "        epochs=10,\n",
        "        lr=1e-3,\n",
        "    )\n",
        "\n",
        "tag2idx = {'O':0, \n",
        "           'B-ORG':1, 'I-ORG':2, \n",
        "           'B-LOC':3, 'I-LOC':4, \n",
        "           'B-PER':5, 'I-PER':6}\n",
        "\n",
        "train_pathx = MAIN_PATH+'msra/train/sentences.txt'\n",
        "train_pathy = MAIN_PATH+'msra/train/tags.txt'\n",
        "val_pathx = MAIN_PATH+'msra/val/sentences.txt'\n",
        "val_pathy = MAIN_PATH+'msra/val/tags.txt'\n",
        "test_pathx = MAIN_PATH+'msra/test/sentences.txt'\n",
        "test_pathy = MAIN_PATH+'msra/test/tags.txt'\n",
        "\n",
        "print('model params:', model_config)\n",
        "print('data params:', data_config)\n",
        "print('train parmas:', train_config)\n",
        "print('tag2idx:', tag2idx)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model params: {'target_size': 7}\n",
            "data params: {'seq_len': 200, 'batch_size': 8}\n",
            "train parmas: {'epochs': 10, 'lr': 0.001}\n",
            "tag2idx: {'O': 0, 'B-ORG': 1, 'I-ORG': 2, 'B-LOC': 3, 'I-LOC': 4, 'B-PER': 5, 'I-PER': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8kmRBlnPIC_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "4e4bb33f73394303a8afa4776c8faf3e",
            "0214674dd2ff4b669923db5fefcfe146",
            "5dc69c1a929e47e6be6dfb04e2c11621",
            "aa924d8ef48c46b78e105ea5269683d5",
            "c6ab156ee3d54ea29b404dc114c954cb",
            "a287e4d18b974a569ff8f878b356e507",
            "678a911f26f04292b280e698e7648eff",
            "48d2737939934b1db2880de404ae62e8"
          ]
        },
        "outputId": "b8430197-9426-4b7b-cd36-cc2bfc157bc8"
      },
      "source": [
        "# bert fine-tuning for ner task\n",
        "\n",
        "# get bert tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "#model = BertForTokenClassification.from_pretrained('bert-base-chinese')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4e4bb33f73394303a8afa4776c8faf3e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, description='Downloading', max=109540, style=ProgressStyle(description_wid…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CoZGwBDMfZFn",
        "outputId": "ed68e28a-9a59-49e9-b22c-37fadc70dc45",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# prepare train data\n",
        "train_token = open(train_pathx, 'r').read().split('\\n')[:-1]\n",
        "train_target = open(train_pathy, 'r').read().split('\\n')[:-1]\n",
        "\n",
        "print(tokenizer.tokenize(train_token[10]))\n",
        "print(train_target[10].split(' '))\n",
        "token_0 = tokenizer.encode_plus(train_token[0], max_length=10, pad_to_max_length=True)\n",
        "print(len(token_0['input_ids']))\n",
        "\n",
        "for key in token_0:\n",
        "    print(key, ':')\n",
        "    print(token_0[key])\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in token_0['input_ids']]))\n",
        "#train_token = tokenizer.batch_encode_plus(train_token, pad_to_max_length=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['当', '有', '了', '一', '定', '的', '实', '力', '后', '，', '他', '就', '成', '立', '了', '武', '义', '县', '重', '点', '实', '用', '菌', '公', '司', '，', '不', '仅', '负', '责', '为', '菇', '农', '提', '供', '技', '术', '指', '导', '和', '菌', '种', '，', '而', '且', '负', '责', '原', '料', '代', '购', '，', '产', '品', '回', '收', '，', '经', '自', '己', '加', '工', '，', '或', '出', '口', '、', '或', '内', '销', '，', '从', '而', '使', '高', '温', '香', '菇', '栽', '培', '技', '术', '迅', '速', '扩', '散', '到', '浙', '西', '南', '山', '区', '的', '１', '０', '多', '个', '县', '市', '，', '１', '０', '０', '多', '个', '乡', '镇', '，', '栽', '培', '规', '模', '由', '１', '９', '９', '１', '年', '的', '２', '３', '万', '袋', '增', '加', '到', '１', '９', '９', '５', '年', '的', '３', '０', '０', '０', '万', '袋', '，', '仅', '此', '一', '项', '就', '使', '当', '地', '农', '民', '增', '加', '收', '入', '１', '亿', '多', '元', '。']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "10\n",
            "input_ids :\n",
            "[101, 1963, 862, 6237, 1104, 6639, 4413, 4518, 7270, 102]\n",
            "token_type_ids :\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask :\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Tokens (str)      : ['[CLS]', '如', '何', '解', '决', '足', '球', '界', '长', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgAjJakpPIDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建数据集\n",
        "class MSRA(Dataset):\n",
        "    \n",
        "    def __init__(self, seq_len, train_token_path, train_target_path, device=device):\n",
        "        \n",
        "        # load raw data\n",
        "        train_token = open(train_token_path, 'r').read().split('\\n')[:-1]\n",
        "        train_target = open(train_target_path, 'r').read().split('\\n')[:-1]\n",
        "        \n",
        "        # tokenize\n",
        "        self.train_token = list(map(lambda x:['[CLS]']+x.split(' ')[:seq_len-2]+['[SEP]'], train_token))\n",
        "        self.train_target = list(map(lambda x:['O']+x.split(' ')[:seq_len-2]+['O'], train_target))\n",
        "        \n",
        "        # check\n",
        "        for token, target in zip(self.train_token, self.train_target):\n",
        "            if len(token) != len(target):\n",
        "                print(idx, token, target)\n",
        "                print('-'*100)\n",
        "        \n",
        "        # transform to id list\n",
        "        self.train_token = list(map(lambda x:tokenizer.convert_tokens_to_ids(x), self.train_token))\n",
        "        self.train_target = list(map(lambda x:[tag2idx[i] for i in x], self.train_target))\n",
        "        \n",
        "        # pad and mask\n",
        "        pad_lens = [seq_len-len(x) for x in self.train_token]\n",
        "        self.train_token = [token+[0]*pad_len for token, pad_len in zip(self.train_token, pad_lens)]\n",
        "        self.mask = [[1]*(seq_len-pad_len)+[0]*pad_len for pad_len in pad_lens]\n",
        "        self.train_target = [target+[0]*pad_len for target, pad_len in zip(self.train_target, pad_lens)]\n",
        "        \n",
        "        # to tensor\n",
        "        self.train_token = torch.LongTensor(self.train_token).to(device)\n",
        "        self.mask = torch.LongTensor(self.mask).to(device)\n",
        "        self.train_target = torch.LongTensor(self.train_target).to(device)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return self.train_token[idx], self.mask[idx], self.train_target[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.train_token)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQJzbwgSPIDJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "outputId": "76f6ba0f-c04d-4601-e96f-680914693107"
      },
      "source": [
        "train_data = MSRA(data_config['seq_len'], train_pathx, train_pathy)\n",
        "print(train_data[10])\n",
        "train_data_loader = DataLoader(train_data, batch_size=data_config['batch_size'])\n",
        "\n",
        "val_data = MSRA(data_config['seq_len'], val_pathx, val_pathy)\n",
        "val_data_loader = DataLoader(val_data, batch_size=data_config['batch_size'])\n",
        "\n",
        "test_data = MSRA(data_config['seq_len'], test_pathx, test_pathy)\n",
        "test_data_loader = DataLoader(test_data, batch_size=data_config['batch_size'])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 101, 2496, 3300,  749,  671, 2137, 4638, 2141, 1213, 1400, 8024,  800,\n",
            "        2218, 2768, 4989,  749, 3636,  721, 1344, 7028, 4157, 2141, 4500, 5826,\n",
            "        1062, 1385, 8024,  679,  788, 6566, 6569,  711, 5823, 1093, 2990,  897,\n",
            "        2825, 3318, 2900, 2193, 1469, 5826, 4905, 8024, 5445,  684, 6566, 6569,\n",
            "        1333, 3160,  807, 6579, 8024,  772, 1501, 1726, 3119, 8024, 5307, 5632,\n",
            "        2346, 1217, 2339, 8024, 2772, 1139, 1366,  510, 2772, 1079, 7218, 8024,\n",
            "         794, 5445,  886, 7770, 3946, 7676, 5823, 3420, 1824, 2825, 3318, 6813,\n",
            "        6862, 2810, 3141, 1168, 3851, 6205, 1298, 2255, 1277, 4638, 8029, 8028,\n",
            "        1914,  702, 1344, 2356, 8024, 8029, 8028, 8028, 1914,  702,  740, 7252,\n",
            "        8024, 3420, 1824, 6226, 3563, 4507, 8029, 8037, 8037, 8029, 2399, 4638,\n",
            "        8030, 8031,  674, 6150, 1872, 1217, 1168, 8029, 8037, 8037, 8033, 2399,\n",
            "        4638, 8031, 8028, 8028, 8028,  674, 6150, 8024,  788, 3634,  671, 7555,\n",
            "        2218,  886, 2496, 1765, 1093, 3696, 1872, 1217, 3119, 1057, 8029,  783,\n",
            "        1914, 1039,  511,  102,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0], device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-omtDVXMfZFq",
        "outputId": "a8838fba-f711-4f05-c881-c1ef14849ccc",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "c0a8fbefa8bb45998c5a6d678280dbf2"
          ]
        }
      },
      "source": [
        "# evaluate trained model on some cases\n",
        "def evaluation_case(model, n=1):\n",
        "    x, mask, y = next(val_data_loader)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tag_prob = model(input_ids=x, attention_mask=mask, labels=y)[1] # score\n",
        "      tag_pred = np.argmax(tag_pred.numpy(), -1)\n",
        "      for sent, tag in zip(x[:n].numpy(), tag_pred[:n]):\n",
        "        print('\\t',[token_idx_r.get(i,'')+':'+tag2idx_r[j] for i,j in zip(sent, tag)])\n",
        "\n",
        "# train model and evaluation\n",
        "def train(model_config, train_config, device=device):\n",
        "    \n",
        "    print('training start...')\n",
        "    print('[params]:')\n",
        "    print('\\tmodel params:', model_config)\n",
        "    print('\\ttrain parmas:', train_config)\n",
        "\n",
        "    # build model\n",
        "    bertmodel = BertForTokenClassification.from_pretrained('bert-base-chinese', num_labels=model_config['target_size']).to(device)\n",
        "    print('[build model]:')\n",
        "    print(bertmodel.parameters())\n",
        "    \n",
        "    # opt\n",
        "    optimizer = AdamW(bertmodel.parameters(), lr=train_config['lr'])\n",
        "    \n",
        "    # train\n",
        "    for epoch in range(train_config['epochs']):\n",
        "        \n",
        "        # record loss every epoch\n",
        "        loss_value = []\n",
        "        \n",
        "        for token, mask, target in tqdm_notebook(train_data_loader):\n",
        "\n",
        "            # model init\n",
        "            optimizer.zero_grad()\n",
        "            bertmodel.train()\n",
        "            \n",
        "            loss = bertmodel(input_ids=token, attention_mask=mask, labels=target)[0]\n",
        "            \n",
        "            # record\n",
        "            loss_value.append(loss.item())\n",
        "            \n",
        "            # weight update\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        print('[epoch %d]\\tloss=%s' % (epoch, np.mean(loss_value)))\n",
        "        #print('all loss:', loss_value)\n",
        "        print('[evaluation]:')\n",
        "        #evaluation_case(model, n=2)\n",
        "        \n",
        "    return model\n",
        "\n",
        "model = train(model_config, train_config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training start...\n",
            "[params]:\n",
            "\tmodel params: {'target_size': 7}\n",
            "\ttrain parmas: {'epochs': 10, 'lr': 0.001}\n",
            "[build model]:\n",
            "<generator object Module.parameters at 0x7f4b4f53a2b0>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0a8fbefa8bb45998c5a6d678280dbf2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5250), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6eO4SE1PIDP",
        "colab_type": "code",
        "colab": {
          "referenced_widgets": [
            "1ca5360f70684362a40d7d648fb3f0f3"
          ]
        },
        "outputId": "9b615216-56b2-44c2-bf4a-da96ac433278"
      },
      "source": [
        "#test\n",
        "\n",
        "def test(model, out_pathx, out_pathy, path_x=MAIN_PATH+'msra/test/sentences.txt', path_y=MAIN_PATH+'msra/test/tags.txt'):\n",
        "    Iter_val = train_data_iter(path_x, path_y, data_config, shuffle=False)\n",
        "    ox = open(out_pathx, 'w')\n",
        "    oy = open(out_pathy, 'w')\n",
        "    \n",
        "    model.eval()\n",
        "    for x,y in tqdm_notebook(Iter_val):\n",
        "        with torch.no_grad():\n",
        "            tag_pred = model(x)\n",
        "            for sent, tag in zip(x.numpy(), tag_pred):\n",
        "                sent_decode = ' '.join([token_idx_r[i] for i in sent])\n",
        "                tag_decode = ' '.join([tag_idx_r[i] for i in tag])\n",
        "                ox.write(sent_decode + '\\n')\n",
        "                oy.write(tag_decode + '\\n')\n",
        "    ox.close()\n",
        "    oy.close()\n",
        "    \n",
        "test(model, out_pathx='result/lstm_crf_sentences.txt', out_pathy='result/lstm_crf_tags.txt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ca5360f70684362a40d7d648fb3f0f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1EG1q4qPIDR",
        "colab_type": "code",
        "colab": {},
        "outputId": "b14fd61b-74b1-4224-fe80-71a6ddbb0d86"
      },
      "source": [
        "# evaluation\n",
        "from utils.evaluation import f1_score_from_path\n",
        "\n",
        "test_x = 'msra/test/sentences.txt'\n",
        "test_y = 'msra/test/tags.txt'\n",
        "pred_y = 'result/lstm_crf_tags.txt'\n",
        "pred_x = 'result/lstm_crf_sentences.txt' # Because of padding, the length of prediction may be shorter than true label\n",
        "\n",
        "micro_score = f1_score_from_path(test_x, test_y, pred_y, pred_x, f1_type='mirco')\n",
        "macro_score = f1_score_from_path(test_x, test_y, pred_y, pred_x, f1_type='marco')\n",
        "print('micro : %s \\t macro : %s' % (micro_score, macro_score))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "micro : 0.8097027292120667 \t macro : 0.8097027292120667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBJFuX8vPIDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}