{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_crf_baseline.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I5GMUBhNfZFW",
        "outputId": "9e13e580-ed1f-4fc8-d224-324aef0c17e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow==2.1.0\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertForTokenClassification, AdamW\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "from tqdm import tqdm_notebook"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.17.5)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.27.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.10.0)\n",
            "Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.1.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.1.0)\n",
            "Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.11.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.9.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow==2.1.0) (45.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hHz1jzC00vrQ",
        "outputId": "f695e5f4-2b22-4e5d-aacc-1ea9a9c4b59d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!/opt/bin/nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Mar  8 11:52:26 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 418.67       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MDzTyqSDfsmu",
        "outputId": "01b355c6-b849-4a27-a780-36396bbb2cb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r41554Laf4uj",
        "outputId": "1c9d294a-cc6d-4b11-8a04-5c72ba043faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load data\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "  from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "\n",
        "  gdd.download_file_from_google_drive(\n",
        "          file_id='1RFZmH6cLFbivA0VeDc6s56bRTgc2NhL1',\n",
        "          dest_path='NER_Data/vocab.txt',\n",
        "      )\n",
        "\n",
        "  gdd.download_file_from_google_drive(\n",
        "          file_id='1JqV332A6ZWZEHv64vzCFmSNVpC1Mox8J',\n",
        "          dest_path='NER_Data/msra.zip',\n",
        "          unzip=True\n",
        "      )\n",
        "  print('running in colab!')\n",
        "  MAIN_PATH = '/content/NER_Data/'\n",
        "except:\n",
        "  print('running in local environment!')\n",
        "  MAIN_PATH = './'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "running in colab!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NtzaciW3fZFc",
        "outputId": "c931d1ae-ceb2-4942-a25c-750c11c63b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# params for model\n",
        "model_config = dict(\n",
        "        target_size=7\n",
        "    )\n",
        "\n",
        "# params for data processing\n",
        "data_config = dict(\n",
        "        seq_len=128,\n",
        "        batch_size=32,\n",
        "    )\n",
        "\n",
        "# params for model training\n",
        "train_config = dict(\n",
        "        epochs=3,\n",
        "        lr=5e-5,\n",
        "        adam_eps=1e-8\n",
        "    )\n",
        "\n",
        "tag2idx = {'O':0, \n",
        "           'B-ORG':1, 'I-ORG':2, \n",
        "           'B-LOC':3, 'I-LOC':4, \n",
        "           'B-PER':5, 'I-PER':6}\n",
        "\n",
        "train_pathx = MAIN_PATH+'msra/train/sentences.txt'\n",
        "train_pathy = MAIN_PATH+'msra/train/tags.txt'\n",
        "val_pathx = MAIN_PATH+'msra/val/sentences.txt'\n",
        "val_pathy = MAIN_PATH+'msra/val/tags.txt'\n",
        "test_pathx = MAIN_PATH+'msra/test/sentences.txt'\n",
        "test_pathy = MAIN_PATH+'msra/test/tags.txt'\n",
        "\n",
        "print('model params:', model_config)\n",
        "print('data params:', data_config)\n",
        "print('train parmas:', train_config)\n",
        "print('tag2idx:', tag2idx)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model params: {'target_size': 7}\n",
            "data params: {'seq_len': 128, 'batch_size': 16}\n",
            "train parmas: {'epochs': 3, 'lr': 5e-05, 'adam_eps': 1e-08}\n",
            "tag2idx: {'O': 0, 'B-ORG': 1, 'I-ORG': 2, 'B-LOC': 3, 'I-LOC': 4, 'B-PER': 5, 'I-PER': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8kmRBlnPIC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bert fine-tuning for ner task\n",
        "\n",
        "# get bert tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "#model = BertForTokenClassification.from_pretrained('bert-base-chinese')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CoZGwBDMfZFn",
        "outputId": "edae9ecc-eeb7-478f-8d81-50188d8d44cc",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "# prepare train data\n",
        "train_token = open(train_pathx, 'r').read().split('\\n')[:-1]\n",
        "train_target = open(train_pathy, 'r').read().split('\\n')[:-1]\n",
        "\n",
        "print(tokenizer.tokenize(train_token[10]))\n",
        "print(train_target[10].split(' '))\n",
        "token_0 = tokenizer.encode_plus(train_token[0], max_length=10, pad_to_max_length=True)\n",
        "print(len(token_0['input_ids']))\n",
        "\n",
        "for key in token_0:\n",
        "    print(key, ':')\n",
        "    print(token_0[key])\n",
        "print(\"Tokens (str)      : {}\".format([tokenizer.convert_ids_to_tokens(s) for s in token_0['input_ids']]))\n",
        "#train_token = tokenizer.batch_encode_plus(train_token, pad_to_max_length=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['当', '有', '了', '一', '定', '的', '实', '力', '后', '，', '他', '就', '成', '立', '了', '武', '义', '县', '重', '点', '实', '用', '菌', '公', '司', '，', '不', '仅', '负', '责', '为', '菇', '农', '提', '供', '技', '术', '指', '导', '和', '菌', '种', '，', '而', '且', '负', '责', '原', '料', '代', '购', '，', '产', '品', '回', '收', '，', '经', '自', '己', '加', '工', '，', '或', '出', '口', '、', '或', '内', '销', '，', '从', '而', '使', '高', '温', '香', '菇', '栽', '培', '技', '术', '迅', '速', '扩', '散', '到', '浙', '西', '南', '山', '区', '的', '１', '０', '多', '个', '县', '市', '，', '１', '０', '０', '多', '个', '乡', '镇', '，', '栽', '培', '规', '模', '由', '１', '９', '９', '１', '年', '的', '２', '３', '万', '袋', '增', '加', '到', '１', '９', '９', '５', '年', '的', '３', '０', '０', '０', '万', '袋', '，', '仅', '此', '一', '项', '就', '使', '当', '地', '农', '民', '增', '加', '收', '入', '１', '亿', '多', '元', '。']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
            "10\n",
            "input_ids :\n",
            "[101, 1963, 862, 6237, 1104, 6639, 4413, 4518, 7270, 102]\n",
            "token_type_ids :\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "attention_mask :\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Tokens (str)      : ['[CLS]', '如', '何', '解', '决', '足', '球', '界', '长', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgAjJakpPIDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 构建数据集\n",
        "class MSRA(Dataset):\n",
        "    \n",
        "    def __init__(self, seq_len, train_token_path, train_target_path, device=device):\n",
        "        \n",
        "        # load raw data\n",
        "        train_token = open(train_token_path, 'r').read().split('\\n')[:-1]\n",
        "        train_target = open(train_target_path, 'r').read().split('\\n')[:-1]\n",
        "        \n",
        "        # tokenize\n",
        "        self.train_token = list(map(lambda x:['[CLS]']+x.split(' ')[:seq_len-2]+['[SEP]'], train_token))\n",
        "        self.train_target = list(map(lambda x:['O']+x.split(' ')[:seq_len-2]+['O'], train_target))\n",
        "        \n",
        "        # check\n",
        "        for token, target in zip(self.train_token, self.train_target):\n",
        "            if len(token) != len(target):\n",
        "                print(idx, token, target)\n",
        "                print('-'*100)\n",
        "        \n",
        "        # transform to id list\n",
        "        self.train_token = list(map(lambda x:tokenizer.convert_tokens_to_ids(x), self.train_token))\n",
        "        self.train_target = list(map(lambda x:[tag2idx[i] for i in x], self.train_target))\n",
        "        \n",
        "        # pad and mask\n",
        "        pad_lens = [seq_len-len(x) for x in self.train_token]\n",
        "        self.train_token = [token+[0]*pad_len for token, pad_len in zip(self.train_token, pad_lens)]\n",
        "        self.mask = [[1]*(seq_len-pad_len)+[0]*pad_len for pad_len in pad_lens]\n",
        "        self.train_target = [target+[0]*pad_len for target, pad_len in zip(self.train_target, pad_lens)]\n",
        "        \n",
        "        # to tensor\n",
        "        self.train_token = torch.LongTensor(self.train_token).to(device)\n",
        "        self.mask = torch.LongTensor(self.mask).to(device)\n",
        "        self.train_target = torch.LongTensor(self.train_target).to(device)\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        return self.train_token[idx], self.mask[idx], self.train_target[idx]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.train_token)\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQJzbwgSPIDJ",
        "colab_type": "code",
        "outputId": "d2e3a4a5-6fd1-4272-b29f-dadb5150c5a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "train_data = MSRA(data_config['seq_len'], train_pathx, train_pathy)\n",
        "print(train_data[10])\n",
        "train_data_loader = DataLoader(train_data, batch_size=data_config['batch_size'])\n",
        "\n",
        "val_data = MSRA(data_config['seq_len'], val_pathx, val_pathy)\n",
        "val_data_loader = DataLoader(val_data, batch_size=data_config['batch_size'])\n",
        "\n",
        "test_data = MSRA(data_config['seq_len'], test_pathx, test_pathy)\n",
        "test_data_loader = DataLoader(test_data, batch_size=data_config['batch_size'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([ 101, 2496, 3300,  749,  671, 2137, 4638, 2141, 1213, 1400, 8024,  800,\n",
            "        2218, 2768, 4989,  749, 3636,  721, 1344, 7028, 4157, 2141, 4500, 5826,\n",
            "        1062, 1385, 8024,  679,  788, 6566, 6569,  711, 5823, 1093, 2990,  897,\n",
            "        2825, 3318, 2900, 2193, 1469, 5826, 4905, 8024, 5445,  684, 6566, 6569,\n",
            "        1333, 3160,  807, 6579, 8024,  772, 1501, 1726, 3119, 8024, 5307, 5632,\n",
            "        2346, 1217, 2339, 8024, 2772, 1139, 1366,  510, 2772, 1079, 7218, 8024,\n",
            "         794, 5445,  886, 7770, 3946, 7676, 5823, 3420, 1824, 2825, 3318, 6813,\n",
            "        6862, 2810, 3141, 1168, 3851, 6205, 1298, 2255, 1277, 4638, 8029, 8028,\n",
            "        1914,  702, 1344, 2356, 8024, 8029, 8028, 8028, 1914,  702,  740, 7252,\n",
            "        8024, 3420, 1824, 6226, 3563, 4507, 8029, 8037, 8037, 8029, 2399, 4638,\n",
            "        8030, 8031,  674, 6150, 1872, 1217, 1168,  102], device='cuda:0'), tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2, 2, 2, 2,\n",
            "        2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-omtDVXMfZFq",
        "outputId": "15208441-9efa-497c-ae08-7192cdbb54f9",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate trained model on some cases\n",
        "tag2idx_r = {v:k for k,v in tag2idx.items()}\n",
        "\n",
        "def evaluation_case(model, n=1):\n",
        "    for x, mask, y in val_data_loader:\n",
        "      break\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      tag_prob = model(input_ids=x)[0] # score\n",
        "      tag_pred = np.argmax(tag_prob.cpu().numpy(), -1)\n",
        "      for sent_id, tag in zip(x[:n].cpu().numpy(), tag_pred[:n]):\n",
        "        sent_token = tokenizer.convert_ids_to_tokens(sent_id)\n",
        "        print('\\t',[i+':'+tag2idx_r[j] for i,j in zip(sent_token, tag)])\n",
        "\n",
        "# train model and evaluation\n",
        "def train(model_config, train_config, device=device):\n",
        "    \n",
        "    print('training start...')\n",
        "    print('[params]:')\n",
        "    print('\\tmodel params:', model_config)\n",
        "    print('\\ttrain parmas:', train_config)\n",
        "\n",
        "    # build model\n",
        "    bertmodel = BertForTokenClassification.from_pretrained('bert-base-chinese', num_labels=model_config['target_size']).to(device)\n",
        "    print('[build model]:')\n",
        "    print(bertmodel.parameters())\n",
        "    \n",
        "    # opt\n",
        "    param_optimizer = list(bertmodel.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{'params': [p for n, p in param_optimizer]}]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=train_config['lr'], eps=train_config['adam_eps'])\n",
        "    \n",
        "    # train\n",
        "    for epoch in range(train_config['epochs']):\n",
        "        \n",
        "        print('[evaluation]:')\n",
        "        evaluation_case(bertmodel, n=2)\n",
        "\n",
        "        # record loss every epoch\n",
        "        loss_value = []\n",
        "\n",
        "        # model init\n",
        "        bertmodel.train()\n",
        "        \n",
        "        for token, mask, target in tqdm_notebook(train_data_loader):\n",
        "\n",
        "            bertmodel.zero_grad()\n",
        "            \n",
        "            loss = bertmodel(input_ids=token, attention_mask=mask, labels=target)[0]\n",
        "            \n",
        "            # record\n",
        "            loss_value.append(loss.item())\n",
        "            \n",
        "            # weight update\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "        print('[epoch %d]\\tloss=%s' % (epoch, np.mean(loss_value)))\n",
        "\n",
        "    print('[evaluation]:')\n",
        "    evaluation_case(bertmodel, n=2)\n",
        "        \n",
        "    return bertmodel\n",
        "\n",
        "model = train(model_config, train_config)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training start...\n",
            "[params]:\n",
            "\tmodel params: {'target_size': 7}\n",
            "\ttrain parmas: {'epochs': 3, 'lr': 5e-05, 'adam_eps': 1e-08}\n",
            "[build model]:\n",
            "<generator object Module.parameters at 0x7ff205cc5308>\n",
            "[evaluation]:\n",
            "\t ['[CLS]:I-LOC', '近:I-LOC', '日:B-ORG', '在:B-ORG', '江:B-ORG', '苏:I-LOC', '如:B-PER', '皋:I-ORG', '市:B-LOC', '城:I-LOC', '西:I-LOC', '乡:O', '，:B-ORG', '１:I-LOC', '０:I-LOC', '０:I-LOC', '０:I-LOC', '多:I-LOC', '个:B-ORG', '品:I-LOC', '种:I-LOC', '的:I-LOC', '花:I-LOC', '木:I-LOC', '盆:I-LOC', '景:I-LOC', '，:I-LOC', '千:I-LOC', '姿:I-LOC', '百:I-LOC', '态:I-LOC', '，:B-ORG', '新:I-LOC', '颖:I-LOC', '别:I-LOC', '致:I-LOC', '，:I-LOC', '吸:B-ORG', '引:I-LOC', '了:B-LOC', '成:I-LOC', '千:I-LOC', '上:I-LOC', '万:I-LOC', '的:B-LOC', '游:I-LOC', '客:I-LOC', '、:B-ORG', '顾:I-LOC', '客:I-LOC', '驻:I-LOC', '足:I-LOC', '观:I-LOC', '赏:I-LOC', '、:B-ORG', '选:I-LOC', '购:I-LOC', '。:I-LOC', '[SEP]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC']\n",
            "\t ['[CLS]:O', '大:B-LOC', '家:I-LOC', '认:B-ORG', '为:I-LOC', '，:O', '该:O', '片:I-ORG', '较:O', '全:B-ORG', '面:B-ORG', '、:I-LOC', '系:B-ORG', '统:B-ORG', '、:B-ORG', '形:B-ORG', '象:B-ORG', '地:B-ORG', '反:I-PER', '映:B-ORG', '了:B-ORG', '新:B-ORG', '四:I-LOC', '军:B-ORG', '的:B-ORG', '战:B-ORG', '斗:B-ORG', '历:B-ORG', '史:B-ORG', '，:B-ORG', '揭:B-ORG', '示:B-ORG', '了:B-ORG', '中:B-ORG', '国:B-ORG', '共:I-ORG', '产:B-ORG', '党:I-LOC', '在:B-LOC', '抗:B-ORG', '日:B-ORG', '战:B-ORG', '争:B-ORG', '中:B-ORG', '的:I-LOC', '历:B-ORG', '史:B-ORG', '地:B-ORG', '位:B-ORG', '和:I-LOC', '作:B-ORG', '用:I-LOC', '，:O', '是:I-LOC', '一:I-LOC', '部:B-ORG', '进:I-LOC', '行:I-LOC', '爱:I-ORG', '国:B-ORG', '主:B-ORG', '义:I-LOC', '和:I-LOC', '革:I-ORG', '命:B-ORG', '传:I-LOC', '统:I-LOC', '教:I-LOC', '育:I-LOC', '的:I-LOC', '好:O', '教:I-LOC', '材:I-LOC', '。:I-LOC', '[SEP]:O', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC', '[PAD]:I-LOC']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53de992c3b734d03baa8fb198c2fcb73",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2625), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[epoch 0]\tloss=0.3757697166772116\n",
            "[evaluation]:\n",
            "\t ['[CLS]:O', '近:O', '日:O', '在:O', '江:B-LOC', '苏:I-LOC', '如:O', '皋:I-LOC', '市:O', '城:O', '西:I-LOC', '乡:O', '，:O', '１:O', '０:O', '０:O', '０:O', '多:O', '个:O', '品:O', '种:O', '的:O', '花:O', '木:O', '盆:O', '景:O', '，:O', '千:O', '姿:O', '百:O', '态:O', '，:O', '新:O', '颖:O', '别:O', '致:O', '，:O', '吸:O', '引:O', '了:O', '成:O', '千:O', '上:O', '万:O', '的:O', '游:O', '客:O', '、:O', '顾:O', '客:O', '驻:O', '足:O', '观:O', '赏:O', '、:O', '选:O', '购:O', '。:O', '[SEP]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O']\n",
            "\t ['[CLS]:O', '大:O', '家:O', '认:O', '为:O', '，:O', '该:O', '片:O', '较:O', '全:O', '面:O', '、:O', '系:O', '统:O', '、:O', '形:O', '象:O', '地:O', '反:O', '映:O', '了:O', '新:O', '四:I-ORG', '军:I-ORG', '的:O', '战:O', '斗:O', '历:O', '史:O', '，:O', '揭:O', '示:O', '了:O', '中:B-LOC', '国:I-LOC', '共:I-ORG', '产:I-ORG', '党:I-ORG', '在:O', '抗:O', '日:O', '战:O', '争:O', '中:O', '的:O', '历:O', '史:O', '地:O', '位:O', '和:O', '作:O', '用:O', '，:O', '是:O', '一:O', '部:O', '进:O', '行:O', '爱:O', '国:O', '主:O', '义:O', '和:O', '革:O', '命:O', '传:O', '统:O', '教:O', '育:O', '的:O', '好:O', '教:O', '材:O', '。:O', '[SEP]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1807c5f73c47425fb5a784d34e1c4b24",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2625), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[epoch 1]\tloss=0.1426406116953918\n",
            "[evaluation]:\n",
            "\t ['[CLS]:O', '近:O', '日:O', '在:O', '江:B-LOC', '苏:I-LOC', '如:B-LOC', '皋:I-LOC', '市:I-LOC', '城:I-LOC', '西:I-LOC', '乡:O', '，:O', '１:O', '０:O', '０:O', '０:O', '多:O', '个:O', '品:O', '种:O', '的:O', '花:O', '木:O', '盆:O', '景:O', '，:O', '千:O', '姿:O', '百:O', '态:O', '，:O', '新:O', '颖:O', '别:O', '致:O', '，:O', '吸:O', '引:O', '了:O', '成:O', '千:O', '上:O', '万:O', '的:O', '游:O', '客:O', '、:O', '顾:O', '客:O', '驻:O', '足:O', '观:O', '赏:O', '、:O', '选:O', '购:O', '。:O', '[SEP]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O']\n",
            "\t ['[CLS]:O', '大:O', '家:O', '认:O', '为:O', '，:O', '该:O', '片:O', '较:O', '全:O', '面:O', '、:O', '系:O', '统:O', '、:O', '形:O', '象:O', '地:O', '反:O', '映:O', '了:O', '新:B-ORG', '四:I-ORG', '军:I-ORG', '的:O', '战:O', '斗:O', '历:O', '史:O', '，:O', '揭:O', '示:O', '了:O', '中:B-LOC', '国:I-LOC', '共:I-ORG', '产:I-ORG', '党:I-ORG', '在:O', '抗:O', '日:O', '战:O', '争:O', '中:O', '的:O', '历:O', '史:O', '地:O', '位:O', '和:O', '作:O', '用:O', '，:O', '是:O', '一:O', '部:O', '进:O', '行:O', '爱:O', '国:O', '主:O', '义:O', '和:O', '革:O', '命:O', '传:O', '统:O', '教:O', '育:O', '的:O', '好:O', '教:O', '材:O', '。:O', '[SEP]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8a2ce44ec7f46248c7dcb9189d7c39e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=2625), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[epoch 2]\tloss=0.11094573866824309\n",
            "[evaluation]:\n",
            "\t ['[CLS]:O', '近:O', '日:O', '在:O', '江:B-LOC', '苏:I-LOC', '如:B-LOC', '皋:I-LOC', '市:I-LOC', '城:I-LOC', '西:I-LOC', '乡:I-LOC', '，:O', '１:O', '０:O', '０:O', '０:O', '多:O', '个:O', '品:O', '种:O', '的:O', '花:O', '木:O', '盆:O', '景:O', '，:O', '千:O', '姿:O', '百:O', '态:O', '，:O', '新:O', '颖:O', '别:O', '致:O', '，:O', '吸:O', '引:O', '了:O', '成:O', '千:O', '上:O', '万:O', '的:O', '游:O', '客:O', '、:O', '顾:O', '客:O', '驻:O', '足:O', '观:O', '赏:O', '、:O', '选:O', '购:O', '。:O', '[SEP]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O']\n",
            "\t ['[CLS]:O', '大:O', '家:O', '认:O', '为:O', '，:O', '该:O', '片:O', '较:O', '全:O', '面:O', '、:O', '系:O', '统:O', '、:O', '形:O', '象:O', '地:O', '反:O', '映:O', '了:O', '新:B-ORG', '四:I-ORG', '军:I-ORG', '的:O', '战:O', '斗:O', '历:O', '史:O', '，:O', '揭:O', '示:O', '了:O', '中:B-LOC', '国:I-LOC', '共:I-ORG', '产:I-ORG', '党:I-ORG', '在:O', '抗:O', '日:O', '战:O', '争:O', '中:O', '的:O', '历:O', '史:O', '地:O', '位:O', '和:O', '作:O', '用:O', '，:O', '是:O', '一:O', '部:O', '进:O', '行:O', '爱:O', '国:O', '主:O', '义:O', '和:O', '革:O', '命:O', '传:O', '统:O', '教:O', '育:O', '的:O', '好:O', '教:O', '材:O', '。:O', '[SEP]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O', '[PAD]:O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6eO4SE1PIDP",
        "colab_type": "code",
        "outputId": "0c1a2dee-58c7-41c6-d32a-4071d9ab5c7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#test\n",
        "\n",
        "def test(model, out_pathx, out_pathy, path_x=MAIN_PATH+'msra/test/sentences.txt', path_y=MAIN_PATH+'msra/test/tags.txt'):\n",
        "    Iter_val = train_data_iter(path_x, path_y, data_config, shuffle=False)\n",
        "    ox = open(out_pathx, 'w')\n",
        "    oy = open(out_pathy, 'w')\n",
        "    \n",
        "    model.eval()\n",
        "    for x,y in tqdm_notebook(Iter_val):\n",
        "        with torch.no_grad():\n",
        "            tag_pred = model(x)\n",
        "            for sent, tag in zip(x.numpy(), tag_pred):\n",
        "                sent_decode = ' '.join([token_idx_r[i] for i in sent])\n",
        "                tag_decode = ' '.join([tag_idx_r[i] for i in tag])\n",
        "                ox.write(sent_decode + '\\n')\n",
        "                oy.write(tag_decode + '\\n')\n",
        "    ox.close()\n",
        "    oy.close()\n",
        "    \n",
        "test(model, out_pathx='result/lstm_crf_sentences.txt', out_pathy='result/lstm_crf_tags.txt')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-069770f2bae6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0moy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pathx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'result/lstm_crf_sentences.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pathy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'result/lstm_crf_tags.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-069770f2bae6>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, out_pathx, out_pathy, path_x, path_y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pathx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pathy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAIN_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'msra/test/sentences.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mMAIN_PATH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'msra/test/tags.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mIter_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_pathx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0moy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_pathy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data_iter' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1EG1q4qPIDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluation\n",
        "from utils.evaluation import f1_score_from_path\n",
        "\n",
        "test_x = 'msra/test/sentences.txt'\n",
        "test_y = 'msra/test/tags.txt'\n",
        "pred_y = 'result/lstm_crf_tags.txt'\n",
        "pred_x = 'result/lstm_crf_sentences.txt' # Because of padding, the length of prediction may be shorter than true label\n",
        "\n",
        "micro_score = f1_score_from_path(test_x, test_y, pred_y, pred_x, f1_type='mirco')\n",
        "macro_score = f1_score_from_path(test_x, test_y, pred_y, pred_x, f1_type='marco')\n",
        "print('micro : %s \\t macro : %s' % (micro_score, macro_score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBJFuX8vPIDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}